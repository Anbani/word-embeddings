{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from transformers import RobertaConfig\n",
    "from transformers import RobertaTokenizer\n",
    "from transformers import AdamW\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.cuda\n",
    "from transformers import RobertaForMaskedLM\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sentence length: 1211\n",
      "Vocab Size: 18808\n"
     ]
    }
   ],
   "source": [
    "corpus_path = \"../../data/rustaveli/v1/vef_full.txt\"\n",
    "corpus_text = open(corpus_path, \"r\").read()\n",
    "\n",
    "corpus_max_len = max(map(lambda v: len(v), corpus_text.split('.')))\n",
    "corpus_vocab_size = len(set(' '.join(corpus_text.split('.')).split(' ')))\n",
    "\n",
    "print(f\"Maximum sentence length: {corpus_max_len}\")\n",
    "print(f\"Vocab Size: {corpus_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    add_prefix_space=True\n",
    ")\n",
    "\n",
    "tokenizer.train(\n",
    "    files=[corpus_path], \n",
    "    vocab_size=20_000, \n",
    "    min_frequency=1,\n",
    "    special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])\n",
    "\n",
    "tokenizer.save_model('shotabert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('shotabert', max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['რომელმან შექმნა სამყარო ძალითა მით ძლიერითა, ზეგარდმო არსნი სულითა ყვნა ზეცით მონაბერითა, ჩვენ, კაცთა, მოგვცა ქვეყანა, გვაქვს უთვალავი ფერითა, და მისგან არს ყოვლი ხელმწიფე სახითა მის მიერითა',\n",
       " ' ჰე, ღმერთო ერთო, შენ შეჰქმენ სახე ყოვლისა ტანისა, შენ დამიფარე, ძლევა მეც დათრგუნვად მე სატანისა, მომეც მიჯნურთა სურვილი, სიკვდიდმდე გასატანისა, და ცოდვათა შესუბუქება, მუნ თანა წასატანისა']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = corpus_text.split('.')\n",
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1913"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = tokenizer(lines, max_length=512, padding='max_length', truncation=False)\n",
    "len(batch.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1913, 512])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = torch.tensor(batch.input_ids)\n",
    "mask = torch.tensor(batch.attention_mask)\n",
    "\n",
    "input_ids = labels.detach().clone()\n",
    "rand = torch.rand(input_ids.shape)\n",
    "mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 1) * (input_ids != 2)\n",
    "for i in range(input_ids.shape[0]):\n",
    "    selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    input_ids[i, selection] = 3  # our custom [MASK] token == 3\n",
    "\n",
    "\n",
    "encodings = {'input_ids': input_ids, 'attention_mask': mask, 'labels': labels}\n",
    "\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}\n",
    "\n",
    "dataset = Dataset(encodings)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=tokenizer.vocab_size,  # we align this to the tokenizer vocab_size\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = RobertaForMaskedLM(config)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "print(\"Nice.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/george/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "optim = AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "epochs = 200\n",
    "step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        loss = outputs.loss\n",
    "        writer.add_scalar(\"Loss/train\", loss, step)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        step += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('./shotabert') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-19 19:03:35.461252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-19 19:03:35.487374: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-06-19 19:03:35.487392: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-06-19 19:03:35.487758: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "fill = pipeline('fill-mask', model='shotabert', tokenizer='shotabert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.2885054349899292,\n",
       "  'token': 4,\n",
       "  'token_str': '<mask>',\n",
       "  'sequence': 'იყო როსტევან?'},\n",
       " {'score': 0.0005480332183651626,\n",
       "  'token': 0,\n",
       "  'token_str': '<s>',\n",
       "  'sequence': 'იყო როსტევან?'},\n",
       " {'score': 0.00030780278029851615,\n",
       "  'token': 1218,\n",
       "  'token_str': ' პირველ',\n",
       "  'sequence': 'იყო პირველ როსტევან?'},\n",
       " {'score': 0.0003003068850375712,\n",
       "  'token': 3633,\n",
       "  'token_str': ' დიდისა',\n",
       "  'sequence': 'იყო დიდისა როსტევან?'},\n",
       " {'score': 0.00026761656044982374,\n",
       "  'token': 7996,\n",
       "  'token_str': 'ვლილობა',\n",
       "  'sequence': 'იყოვლილობა როსტევან?'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill('იყო <mask> როსტევან?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill(f'თბილისი {fill.tokenizer.mask_token} დედაქალაქია')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ddfca89fb0ff7038606e5fd782b59d233ff8cbd5b2a6aabb29749a82eca2773"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
