{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia dump\n",
    "- Download ```kawiki-latest-pages-articles-multistream.xml``` files from https://dumps.wikimedia.org/kawiki/latest/\n",
    "- Parse text from xml files using WikiExtractor - https://github.com/attardi/wikiextractor\n",
    "- Load ```kawiki.txt``` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nედუარდ შევარდნაძე\\n\\nედუარდ ამბროსის ძე შევარდნაძე (დ. 25 იანვარი, 1928, მამათი, დღევანდელი ლანჩხუთის მუნიციპალიტეტი — გ. 7 ივლისი, 2014, თბილისი) — ქართველი პოლიტიკოსი და სახელმწიფო მოღვაწე. 1985-1990 წლებში საბჭოთა კავშირის საგარეო საქმეთა მინისტრი, 1995–2003 წლებში საქართველოს პრეზიდენტი.\\n\\nსკკპ წევრი 1948 წლიდან. 1946 წლის ივლის-ოქტომბერში მუშაობდა საქართველოს ალკკ თბილისის ორჯონიკიძის რაიკომის ინსტრუქტორად. IX-XI მოწვევების უმაღლესი საბჭოს დეპუტატი. სოციალისტური შრომის გმირი (1981). სკკპ ცკ-'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../txt/kawiki.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    document = file.read()\n",
    "\n",
    "document[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords\n",
    "- Use ```stopwords.txt``` file to clean up Georgian stopwords from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ა.შ.', 'აგერ', 'აგრეთვე', 'ალბათ', 'ამაზე']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../txt/stopwords.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    stopwords = [line.replace('\\n','') for line in file.readlines()]\n",
    "stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 373/373 [12:32<00:00,  2.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  ედუარდ შევარდნაძე  ედუარდ ამბროსის ძე შევარდნაძე (დ. 25 იანვარი, 1928, მამათი, დღევანდელი ლანჩხუთის მუნიციპალიტეტი — გ. 7 ივლისი, 2014, თბილისი) — ქართველი პოლიტიკოსი  სახელმწიფო მოღვაწე. 1985-1990 წლებში საბჭოთა კავშირის საგარეო საქმეთა მინისტრი, 1995–2003 წლებში საქართველოს პრეზიდენტი.  სკკპ წევრი 1948 წლიდან. 1946 წლის ივლის-ოქტომბერში მუშაობდა საქართველოს ალკკ თბილისის ორჯონიკიძის რაიკომის ინსტრუქტორად. IX-XI მოწვევების უმაღლესი საბჭოს დეპუტატი. სოციალისტური შრომის გმირი (1981). სკკპ ცკ-ის'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "for s in tqdm(stopwords):\n",
    "    document = re.sub(r\"\\b\" + s + r\"\\b\", '', document.replace('\\n', ' '))\n",
    "\n",
    "document[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the document into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  ედუარდ შევარდნაძე  ედუარდ ამბროსის ძე შევარდნაძე  დ. 25 იანვარი  1928  მამათი  დღევანდელი ლანჩხუთის მუნიციპალიტეტი — გ. 7 ივლისი  2014  თბილისი  — ქართველი პოლიტიკოსი  სახელმწიფო მოღვაწე',\n",
       " ' 1985-1990 წლებში საბჭოთა კავშირის საგარეო საქმეთა მინისტრი  1995–2003 წლებში საქართველოს პრეზიდენტი',\n",
       " '  სკკპ წევრი 1948 წლიდან',\n",
       " ' 1946 წლის ივლის-ოქტომბერში მუშაობდა საქართველოს ალკკ თბილისის ორჯონიკიძის რაიკომის ინსტრუქტორად',\n",
       " '   -   მოწვევების უმაღლესი საბჭოს დეპუტატი']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re.split(r\"(?<=\\w\\w\\w)\\.\", re.sub(r'[^ა-ჰ0-9\\.\\-—–\\s]',' ', document))\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057879"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lines(sentences):\n",
    "    for line in tqdm(sentences):\n",
    "        yield gensim.utils.simple_preprocess(line, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1057879/1057879 [00:16<00:00, 64324.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(process_lines(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Common parameters to tune:\n",
    "- min_count (int) – Ignores all words with total frequency lower than this.\n",
    "- window (int) – The maximum distance between the current and predicted word within a sentence.\n",
    "- size (int) – Dimensionality of the feature vectors.\n",
    "- compute_loss (bool) – If True, computes and stores loss value which can be retrieved using model.get_latest_training_loss().\n",
    "- workers (int) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "Defaults:\n",
    "```class gensim.models.word2vec.Word2Vec(sentences=None, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None, sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0, negative=5, cbow_mean=1, hashfxn=<built-in function hash>, iter=5, null_word=0, trim_rule=None, sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=())```\n",
    "\n",
    "I'll set ```min_count=3``` to filter typos and mine as deep as possible. ```workers=12``` works best for my CPU (8700K, 6-core, 12-thread).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    accuracy = model.wv.accuracy('../txt/questions-geography-ka.txt')\n",
    "    sum_corr = len(accuracy[-1]['correct'])\n",
    "    sum_incorr = len(accuracy[-1]['incorrect'])\n",
    "    total = sum_corr + sum_incorr\n",
    "    percent = lambda a: a / total * 100 if total != 0 else 0\n",
    "    print('- TS: {}, Correct: {:.4f}%, Incorrect: {:.4f}%'.format(total, percent(sum_corr), percent(sum_incorr)))\n",
    "    return percent(sum_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import time\n",
    "@contextmanager\n",
    "def timeit(s):\n",
    "    start = time.time()\n",
    "    yield\n",
    "    print(f\"[{time.time()-start:3.0f}s] {s}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 38.4190%, Incorrect: 61.5810%\n",
      "[190s]  Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timeit(f\" Done.\"):\n",
    "    model = gensim.models.Word2Vec(tokens, size=300, min_count=2, window=20, workers=12)\n",
    "    model.train(tokens, total_examples=len(tokens), epochs=10)\n",
    "    accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in global variable\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 15.7312%, Incorrect: 84.2688%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[101s] [S:50 MC:2 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|███████                                                                                                                                                                 | 2/48 [01:41<38:47, 50.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 22.1344%, Incorrect: 77.8656%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 95s] [S:50 MC:2 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|██████████▌                                                                                                                                                             | 3/48 [03:15<47:52, 63.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 29.8024%, Incorrect: 70.1976%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 93s] [S:50 MC:2 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|██████████████                                                                                                                                                          | 4/48 [04:49<53:20, 72.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 17.4704%, Incorrect: 82.5296%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 80s] [S:50 MC:8 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█████████████████▌                                                                                                                                                      | 5/48 [06:09<53:47, 75.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 26.0870%, Incorrect: 73.9130%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 80s] [S:50 MC:8 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█████████████████████                                                                                                                                                   | 6/48 [07:29<53:29, 76.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 31.4625%, Incorrect: 68.5375%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 81s] [S:50 MC:8 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|████████████████████████▌                                                                                                                                               | 7/48 [08:50<53:15, 77.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 20.9486%, Incorrect: 79.0514%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 73s] [S:50 MC:16 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|████████████████████████████                                                                                                                                            | 8/48 [10:04<51:02, 76.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 27.4308%, Incorrect: 72.5692%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 73s] [S:50 MC:16 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 19%|███████████████████████████████▌                                                                                                                                        | 9/48 [11:17<49:00, 75.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 30.7510%, Incorrect: 69.2490%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 75s] [S:50 MC:16 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 21%|██████████████████████████████████▊                                                                                                                                    | 10/48 [12:31<47:37, 75.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 20.8524%, Incorrect: 79.1476%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 55s] [S:50 MC:64 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|██████████████████████████████████████▎                                                                                                                                | 11/48 [13:27<42:42, 69.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 27.2451%, Incorrect: 72.7549%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 55s] [S:50 MC:64 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|█████████████████████████████████████████▊                                                                                                                             | 12/48 [14:22<39:00, 65.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 31.8113%, Incorrect: 68.1887%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 56s] [S:50 MC:64 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|█████████████████████████████████████████████▏                                                                                                                         | 13/48 [15:17<36:15, 62.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 19.5257%, Incorrect: 80.4743%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[110s] [S:100 MC:2 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|████████████████████████████████████████████████▋                                                                                                                      | 14/48 [17:08<43:24, 76.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 29.5652%, Incorrect: 70.4348%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[114s] [S:100 MC:2 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 31%|████████████████████████████████████████████████████▏                                                                                                                  | 15/48 [19:01<48:17, 87.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 36.2055%, Incorrect: 63.7945%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[124s] [S:100 MC:2 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███████████████████████████████████████████████████████▋                                                                                                               | 16/48 [21:06<52:40, 98.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 21.2648%, Incorrect: 78.7352%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[109s] [S:100 MC:8 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|██████████████████████████████████████████████████████████▊                                                                                                           | 17/48 [22:55<52:41, 101.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 30.4348%, Incorrect: 69.5652%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[105s] [S:100 MC:8 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|██████████████████████████████████████████████████████████████▎                                                                                                       | 18/48 [24:40<51:25, 102.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 37.3913%, Incorrect: 62.6087%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[104s] [S:100 MC:8 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|█████████████████████████████████████████████████████████████████▋                                                                                                    | 19/48 [26:24<49:52, 103.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 23.9526%, Incorrect: 76.0474%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 93s] [S:100 MC:16 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|█████████████████████████████████████████████████████████████████████▏                                                                                                | 20/48 [27:58<46:47, 100.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 32.9644%, Incorrect: 67.0356%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 91s] [S:100 MC:16 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|█████████████████████████████████████████████████████████████████████████                                                                                              | 21/48 [29:29<43:54, 97.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 41.6601%, Incorrect: 58.3399%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 86s] [S:100 MC:16 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████████████████████████████████████████████████████████████████████████████▌                                                                                          | 22/48 [30:55<40:50, 94.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 25.5708%, Incorrect: 74.4292%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 63s] [S:100 MC:64 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████████████████████████████████████████████████████████████████████████████████                                                                                       | 23/48 [31:58<35:18, 84.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 32.5723%, Incorrect: 67.4277%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 61s] [S:100 MC:64 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████▌                                                                                   | 24/48 [32:59<31:01, 77.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 39.4216%, Incorrect: 60.5784%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 63s] [S:100 MC:64 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|██████████████████████████████████████████████████████████████████████████████████████▉                                                                                | 25/48 [34:01<28:01, 73.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 18.6561%, Incorrect: 81.3439%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[155s] [S:200 MC:2 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████▍                                                                            | 26/48 [36:36<35:49, 97.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 29.4071%, Incorrect: 70.5929%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[154s] [S:200 MC:2 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████████████████████████████████████████████████████████████████████████████████████████████▍                                                                        | 27/48 [39:11<40:07, 114.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 37.6285%, Incorrect: 62.3715%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[154s] [S:200 MC:2 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 28/48 [41:44<42:06, 126.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 19.5257%, Incorrect: 80.4743%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[140s] [S:200 MC:8 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                 | 29/48 [44:04<41:18, 130.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 33.3597%, Incorrect: 66.6403%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[136s] [S:200 MC:8 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                              | 30/48 [46:20<39:35, 131.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 40.8696%, Incorrect: 59.1304%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[130s] [S:200 MC:8 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 31/48 [48:30<37:14, 131.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 21.7391%, Incorrect: 78.2609%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[119s] [S:200 MC:16 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                       | 32/48 [50:29<34:02, 127.65s/it]"
     ]
    }
   ],
   "source": [
    "d = 200\n",
    "mc = 100\n",
    "w = 20\n",
    "\n",
    "dims = [50,100,200,300]\n",
    "mincounts = [2, 8, 16, 64]\n",
    "windows = [2, 4, 8]\n",
    "\n",
    "pbar = tqdm(total=len(dims)*len(mincounts)*len(windows))\n",
    "\n",
    "for i,d in enumerate(dims):\n",
    "    for j,mc in enumerate(mincounts):\n",
    "        for k,w in enumerate(windows):\n",
    "            pbar.update(1)\n",
    "            with timeit(f\"[S:{d} MC:{mc} W:{w}] Model training complete.\"):\n",
    "                model = gensim.models.Word2Vec(tokens, size=d, min_count=mc, window=w, workers=12, compute_loss=True)\n",
    "                model.train(tokens, total_examples=len(tokens), epochs=10)\n",
    "                acc = accuracy(model)\n",
    "                print(f\"- Vocab size:{len(model.wv.vocab)}\\n- Compute Loss: {model.get_latest_training_loss()}\")\n",
    "                results.append({\n",
    "                    'size':d,\n",
    "                    'min_count':mc,\n",
    "                    'window':w,\n",
    "                    'vocab':len(model.wv.vocab),\n",
    "                    'accuracy':acc,\n",
    "                    'loss':model.get_latest_training_loss()\n",
    "                })\n",
    "                \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('რქაწითელი', 0.9220234155654907),\n",
       " ('ქინძმარაული', 0.8812519311904907),\n",
       " ('ციცქა', 0.8682762384414673),\n",
       " ('საადრეო', 0.8441500663757324),\n",
       " ('კრახუნა', 0.8396971821784973),\n",
       " ('ცოლიკოური', 0.8338011503219604),\n",
       " ('ჩხავერი', 0.823092520236969),\n",
       " ('გორული', 0.8198326230049133),\n",
       " ('ჯიშებიდან', 0.8062148690223694),\n",
       " ('ატენური', 0.7817213535308838)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = ['საფერავი']\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogie(a, b, c, model):\n",
    "    return model.wv.most_similar(positive=[b,c], negative=[a], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('რუსეთი', 0.5468760132789612),\n",
       " ('პოლტავა', 0.5239676833152771),\n",
       " ('უკრაინა', 0.5236309170722961),\n",
       " ('მოლდოვა', 0.5170091390609741),\n",
       " ('ოსმალეთი', 0.5034421682357788),\n",
       " ('ვოლინსკის', 0.500557541847229),\n",
       " ('სერბეთი', 0.4980471134185791),\n",
       " ('ჩერნიგოვი', 0.49603569507598877),\n",
       " ('ირანი', 0.49343639612197876),\n",
       " ('ყირიმი', 0.4855012893676758)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogie(\"თბილისი\",\"საქართველო\",\"კიევი\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ჩემი', 0.9271839),\n",
       " ('ჩემს', 0.025721798),\n",
       " ('ვარ', 0.0060025216),\n",
       " ('შენი', 0.005886703),\n",
       " ('შენ', 0.0055993847),\n",
       " ('სამშობლო', 0.0051750545),\n",
       " ('მე', 0.004013303),\n",
       " ('ჩემო', 0.001358541),\n",
       " ('ვართ', 0.00045134505),\n",
       " ('შენს', 0.00038922738)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_output_word(['ჩემი','ხატია','სამშობლო','სახატე','მთელი'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist model\n",
    "- and export as .tsv for http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11s] Model saved\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timeit(\"Model saved\"):\n",
    "    model.save(\"../model/kawiki_1250MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec2tensor(model, tensor_filename, binary=False):\n",
    "    outfiletsv = tensor_filename + '_tensor.tsv'\n",
    "    outfiletsvmeta = tensor_filename + '_metadata.tsv'\n",
    "\n",
    "    with open(outfiletsv, 'w+', encoding='utf-8') as file_vector:\n",
    "        with open(outfiletsvmeta, 'w+', encoding='utf-8') as file_metadata:\n",
    "            file_metadata.write('word\\tcount\\n')\n",
    "            for word in tqdm(model.wv.index2word):\n",
    "                wordstring = gensim.utils.to_utf8(word).decode(\"utf-8\")\n",
    "                countstring = str(model.wv.vocab[word].count)\n",
    "                file_metadata.write(wordstring + '\\t' + countstring + '\\n')\n",
    "                vector_row = '\\t'.join(str(x) for x in model.wv[word])\n",
    "                file_vector.write(vector_row + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 356756/356756 [00:53<00:00, 6651.86it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec2tensor(model,\"../tsv/kawiki_1250MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
