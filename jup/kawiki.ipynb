{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia dump\n",
    "- Download ```kawiki-latest-pages-articles-multistream.xml``` files from https://dumps.wikimedia.org/kawiki/latest/\n",
    "- Parse text from xml files using WikiExtractor - https://github.com/attardi/wikiextractor\n",
    "- Load ```kawiki.txt``` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nედუარდ შევარდნაძე\\n\\nედუარდ ამბროსის ძე შევარდნაძე (დ. 25 იანვარი, 1928, მამათი, დღევანდელი ლანჩხუთის მუნიციპალიტეტი — გ. 7 ივლისი, 2014, თბილისი) — ქართველი პოლიტიკოსი და სახელმწიფო მოღვაწე. 1985-1990 წლებში საბჭოთა კავშირის საგარეო საქმეთა მინისტრი, 1995–2003 წლებში საქართველოს პრეზიდენტი.\\n\\nსკკპ წევრი 1948 წლიდან. 1946 წლის ივლის-ოქტომბერში მუშაობდა საქართველოს ალკკ თბილისის ორჯონიკიძის რაიკომის ინსტრუქტორად. IX-XI მოწვევების უმაღლესი საბჭოს დეპუტატი. სოციალისტური შრომის გმირი (1981). სკკპ ცკ-'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../txt/kawiki.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    document = file.read()\n",
    "\n",
    "document[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords\n",
    "- Use ```stopwords.txt``` file to clean up Georgian stopwords from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ა.შ.', 'აგერ', 'აგრეთვე', 'ალბათ', 'ამაზე']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../txt/stopwords.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    stopwords = [line.replace('\\n','') for line in file.readlines()]\n",
    "stopwords[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 373/373 [12:32<00:00,  2.02s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  ედუარდ შევარდნაძე  ედუარდ ამბროსის ძე შევარდნაძე (დ. 25 იანვარი, 1928, მამათი, დღევანდელი ლანჩხუთის მუნიციპალიტეტი — გ. 7 ივლისი, 2014, თბილისი) — ქართველი პოლიტიკოსი  სახელმწიფო მოღვაწე. 1985-1990 წლებში საბჭოთა კავშირის საგარეო საქმეთა მინისტრი, 1995–2003 წლებში საქართველოს პრეზიდენტი.  სკკპ წევრი 1948 წლიდან. 1946 წლის ივლის-ოქტომბერში მუშაობდა საქართველოს ალკკ თბილისის ორჯონიკიძის რაიკომის ინსტრუქტორად. IX-XI მოწვევების უმაღლესი საბჭოს დეპუტატი. სოციალისტური შრომის გმირი (1981). სკკპ ცკ-ის'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "for s in tqdm(stopwords):\n",
    "    document = re.sub(r\"\\b\" + s + r\"\\b\", '', document.replace('\\n', ' '))\n",
    "\n",
    "document[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the document into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  ედუარდ შევარდნაძე  ედუარდ ამბროსის ძე შევარდნაძე  დ. 25 იანვარი  1928  მამათი  დღევანდელი ლანჩხუთის მუნიციპალიტეტი — გ. 7 ივლისი  2014  თბილისი  — ქართველი პოლიტიკოსი  სახელმწიფო მოღვაწე',\n",
       " ' 1985-1990 წლებში საბჭოთა კავშირის საგარეო საქმეთა მინისტრი  1995–2003 წლებში საქართველოს პრეზიდენტი',\n",
       " '  სკკპ წევრი 1948 წლიდან',\n",
       " ' 1946 წლის ივლის-ოქტომბერში მუშაობდა საქართველოს ალკკ თბილისის ორჯონიკიძის რაიკომის ინსტრუქტორად',\n",
       " '   -   მოწვევების უმაღლესი საბჭოს დეპუტატი']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re.split(r\"(?<=\\w\\w\\w)\\.\", re.sub(r'[^ა-ჰ0-9\\.\\-—–\\s]',' ', document))\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057879"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_lines(sentences):\n",
    "    for line in tqdm(sentences):\n",
    "        yield gensim.utils.simple_preprocess(line, max_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1057879/1057879 [00:16<00:00, 64324.39it/s]\n"
     ]
    }
   ],
   "source": [
    "tokens = list(process_lines(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Common parameters to tune:\n",
    "- min_count (int) – Ignores all words with total frequency lower than this.\n",
    "- window (int) – The maximum distance between the current and predicted word within a sentence.\n",
    "- size (int) – Dimensionality of the feature vectors.\n",
    "- compute_loss (bool) – If True, computes and stores loss value which can be retrieved using model.get_latest_training_loss().\n",
    "- workers (int) – Use these many worker threads to train the model (=faster training with multicore machines).\n",
    "\n",
    "Defaults:\n",
    "```class gensim.models.word2vec.Word2Vec(sentences=None, size=100, alpha=0.025, window=5, min_count=5, max_vocab_size=None, sample=0.001, seed=1, workers=3, min_alpha=0.0001, sg=0, hs=0, negative=5, cbow_mean=1, hashfxn=<built-in function hash>, iter=5, null_word=0, trim_rule=None, sorted_vocab=1, batch_words=10000, compute_loss=False, callbacks=())```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model):\n",
    "    accuracy = model.wv.accuracy('../txt/questions-geography-ka.txt')\n",
    "    sum_corr = len(accuracy[-1]['correct'])\n",
    "    sum_incorr = len(accuracy[-1]['incorrect'])\n",
    "    total = sum_corr + sum_incorr\n",
    "    percent = lambda a: a / total * 100 if total != 0 else 0\n",
    "    print('- TS: {}, Correct: {:.4f}%, Incorrect: {:.4f}%'.format(total, percent(sum_corr), percent(sum_incorr)))\n",
    "    return percent(sum_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import time\n",
    "@contextmanager\n",
    "def timeit(s):\n",
    "    start = time.time()\n",
    "    yield\n",
    "    print(f\"[{time.time()-start:3.0f}s] {s}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 37.5494%, Incorrect: 62.4506%\n",
      "[198s]  Done.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timeit(f\" Done.\"):\n",
    "    model = gensim.models.Word2Vec(tokens, size=300, min_count=2, window=20, workers=12)\n",
    "    model.train(tokens, total_examples=len(tokens), epochs=10)\n",
    "    accuracy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results in global variable\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                | 0/80 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 18.1028%, Incorrect: 81.8972%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 98s] [S:50 MC:2 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|████▏                                                                                                                                                                 | 2/80 [01:37<1:03:25, 48.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 24.0316%, Incorrect: 75.9684%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 96s] [S:50 MC:2 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|██████▏                                                                                                                                                               | 3/80 [03:13<1:20:36, 62.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 29.4071%, Incorrect: 70.5929%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 97s] [S:50 MC:2 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|████████▎                                                                                                                                                             | 4/80 [04:49<1:32:28, 73.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 28.1423%, Incorrect: 71.8577%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 93s] [S:50 MC:2 W:16] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|██████████▍                                                                                                                                                           | 5/80 [06:23<1:38:49, 79.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 25.5336%, Incorrect: 74.4664%\n",
      "- Vocab size:356756\n",
      "- Compute Loss: 0.0\n",
      "[ 94s] [S:50 MC:2 W:32] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|████████████▍                                                                                                                                                         | 6/80 [07:57<1:43:02, 83.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 22.1344%, Incorrect: 77.8656%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 82s] [S:50 MC:8 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|██████████████▌                                                                                                                                                       | 7/80 [09:19<1:41:03, 83.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 26.5613%, Incorrect: 73.4387%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 81s] [S:50 MC:8 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|████████████████▌                                                                                                                                                     | 8/80 [10:40<1:38:59, 82.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 31.2253%, Incorrect: 68.7747%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 83s] [S:50 MC:8 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|██████████████████▋                                                                                                                                                   | 9/80 [12:03<1:37:55, 82.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 28.6957%, Incorrect: 71.3043%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 86s] [S:50 MC:8 W:16] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|████████████████████▋                                                                                                                                                | 10/80 [13:29<1:37:39, 83.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 26.4822%, Incorrect: 73.5178%\n",
      "- Vocab size:112549\n",
      "- Compute Loss: 0.0\n",
      "[ 85s] [S:50 MC:8 W:32] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|██████████████████████▋                                                                                                                                              | 11/80 [14:54<1:36:33, 83.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 19.9209%, Incorrect: 80.0791%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 73s] [S:50 MC:16 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|████████████████████████▊                                                                                                                                            | 12/80 [16:07<1:31:32, 80.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 24.8221%, Incorrect: 75.1779%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 75s] [S:50 MC:16 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|██████████████████████████▊                                                                                                                                          | 13/80 [17:22<1:28:21, 79.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 31.6996%, Incorrect: 68.3004%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 75s] [S:50 MC:16 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 18%|████████████████████████████▊                                                                                                                                        | 14/80 [18:37<1:25:39, 77.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 30.4348%, Incorrect: 69.5652%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 76s] [S:50 MC:16 W:16] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 19%|██████████████████████████████▉                                                                                                                                      | 15/80 [19:53<1:23:50, 77.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 1265, Correct: 24.1897%, Incorrect: 75.8103%\n",
      "- Vocab size:66060\n",
      "- Compute Loss: 0.0\n",
      "[ 76s] [S:50 MC:16 W:32] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|█████████████████████████████████                                                                                                                                    | 16/80 [21:09<1:22:07, 76.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 20.0913%, Incorrect: 79.9087%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 55s] [S:50 MC:64 W:2] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 21%|███████████████████████████████████                                                                                                                                  | 17/80 [22:04<1:13:46, 70.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 27.7017%, Incorrect: 72.2983%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 55s] [S:50 MC:64 W:4] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 22%|█████████████████████████████████████▏                                                                                                                               | 18/80 [22:59<1:08:01, 65.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 33.6377%, Incorrect: 66.3623%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 55s] [S:50 MC:64 W:8] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 24%|███████████████████████████████████████▏                                                                                                                             | 19/80 [23:55<1:03:38, 62.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 32.8767%, Incorrect: 67.1233%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 60s] [S:50 MC:64 W:16] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 25%|█████████████████████████████████████████▎                                                                                                                           | 20/80 [24:54<1:01:46, 61.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TS: 657, Correct: 30.5936%, Incorrect: 69.4064%\n",
      "- Vocab size:22082\n",
      "- Compute Loss: 0.0\n",
      "[ 58s] [S:50 MC:64 W:32] Model training complete.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 26%|███████████████████████████████████████████▊                                                                                                                           | 21/80 [25:52<59:29, 60.51s/it]"
     ]
    }
   ],
   "source": [
    "d = 200\n",
    "mc = 100\n",
    "w = 20\n",
    "\n",
    "dims = [50,100,200,300]\n",
    "mincounts = [2, 8, 16, 64]\n",
    "windows = [2, 4, 8, 16, 32]\n",
    "\n",
    "pbar = tqdm(total=len(dims)*len(mincounts)*len(windows))\n",
    "\n",
    "for i,d in enumerate(dims):\n",
    "    for j,mc in enumerate(mincounts):\n",
    "        for k,w in enumerate(windows):\n",
    "            pbar.update(1)\n",
    "            with timeit(f\"[S:{d} MC:{mc} W:{w}] Model training complete.\"):\n",
    "                model = gensim.models.Word2Vec(tokens, size=d, min_count=mc, window=w, workers=12, compute_loss=True)\n",
    "                model.train(tokens, total_examples=len(tokens), epochs=10)\n",
    "                acc = accuracy(model)\n",
    "                print(f\"- Vocab size:{len(model.wv.vocab)}\\n- Compute Loss: {model.get_latest_training_loss()}\")\n",
    "                results.append({\n",
    "                    'size':d,\n",
    "                    'min_count':mc,\n",
    "                    'window':w,\n",
    "                    'vocab':len(model.wv.vocab),\n",
    "                    'accuracy':acc,\n",
    "                    'loss':model.get_latest_training_loss()\n",
    "                })\n",
    "                \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('რქაწითელი', 0.8808282613754272),\n",
       " ('ციცქა', 0.867584228515625),\n",
       " ('კრახუნა', 0.860209584236145),\n",
       " ('ცოლიკოური', 0.8515080213546753),\n",
       " ('ქინძმარაული', 0.8172898888587952)]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = ['საფერავი']\n",
    "model.wv.most_similar(positive=w1, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('მერჩულეს', 0.5412800312042236),\n",
       " ('დანელიას', 0.509667694568634),\n",
       " ('მერჩულიულნის', 0.4998641908168793),\n",
       " ('ბრწყინვალის', 0.4979133605957031),\n",
       " ('მთაწმიდელის', 0.48206937313079834),\n",
       " ('ასანიშვილი', 0.4561194181442261),\n",
       " ('სააკაძე', 0.45581313967704773),\n",
       " ('მერჩულე', 0.4496610760688782),\n",
       " ('მთაწმიდლის', 0.446776807308197),\n",
       " ('პერანგითა', 0.4463770389556885)]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = ['გიორგი', 'აღმაშენებელი']\n",
    "w2 = ['დავით']\n",
    "model.wv.most_similar(positive=w1, negative=w2, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analogie(a, b, c, model, **kwargs):\n",
    "    return model.wv.most_similar(positive=[b,c], negative=[a], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('უკრაინა', 0.5557381510734558), ('პოლტავა', 0.5374630093574524)]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogie(\"თბილისი\", \"საქართველო\", \"კიევი\", model, topn=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ლურჯი', 0.45027443766593933), ('სალაკა', 0.44323498010635376)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogie(\"ცა\", \"ცისფერი\", \"ზღვა\", model, topn=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist model\n",
    "- and export as .tsv for http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 11s] Model saved\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with timeit(\"Model saved\"):\n",
    "    model.save(\"../model/kawiki_1250MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec2tensor(model, tensor_filename, binary=False):\n",
    "    outfiletsv = tensor_filename + '_tensor.tsv'\n",
    "    outfiletsvmeta = tensor_filename + '_metadata.tsv'\n",
    "\n",
    "    with open(outfiletsv, 'w+', encoding='utf-8') as file_vector:\n",
    "        with open(outfiletsvmeta, 'w+', encoding='utf-8') as file_metadata:\n",
    "            file_metadata.write('word\\tcount\\n')\n",
    "            for word in tqdm(model.wv.index2word):\n",
    "                wordstring = gensim.utils.to_utf8(word).decode(\"utf-8\")\n",
    "                countstring = str(model.wv.vocab[word].count)\n",
    "                file_metadata.write(wordstring + '\\t' + countstring + '\\n')\n",
    "                vector_row = '\\t'.join(str(x) for x in model.wv[word])\n",
    "                file_vector.write(vector_row + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 356756/356756 [00:53<00:00, 6651.86it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec2tensor(model,\"../tsv/kawiki_1250MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
